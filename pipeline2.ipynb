{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.stats import gaussian_kde, chi2\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def process_image(image_path, output_path, threshold=None, quantile=0.99936, alpha=1.5):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if image is None:\n",
    "        raise FileNotFoundError(f\"Image not found: {image_path}\")\n",
    "    \n",
    "    _, binary = cv2.threshold(image, 128, 255, cv2.THRESH_BINARY_INV)\n",
    "    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(binary, connectivity=8)\n",
    "    segment_areas = stats[1:, cv2.CC_STAT_AREA]  # Ignore background label\n",
    "    \n",
    "    def find_effective_threshold():\n",
    "        if segment_areas.size == 0:\n",
    "            return 0\n",
    "        kde = gaussian_kde(segment_areas)\n",
    "        x_vals = np.linspace(segment_areas.min(), segment_areas.max(), 500)\n",
    "        y_vals = kde(x_vals)\n",
    "        d2y_dx2 = np.gradient(np.gradient(y_vals, x_vals), x_vals)\n",
    "        return float(x_vals[np.argmax(d2y_dx2)])\n",
    "    \n",
    "    if threshold is None:\n",
    "        threshold = find_effective_threshold()\n",
    "    threshold = float(threshold)\n",
    "    \n",
    "    filtered_labels = np.where(segment_areas >= threshold)[0] + 1  # Labels start from 1\n",
    "    filtered_image = np.isin(labels, filtered_labels).astype(np.uint8) * 255\n",
    "    \n",
    "    contours, _ = cv2.findContours(filtered_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if len(contours) == 0:\n",
    "        cv2.imwrite(output_path, filtered_image)\n",
    "        return filtered_image, output_path\n",
    "    \n",
    "    features = np.array([[cv2.boundingRect(c)[2] / max(cv2.boundingRect(c)[3], 1),\n",
    "                          cv2.contourArea(c),\n",
    "                          cv2.contourArea(c) / (cv2.boundingRect(c)[2] * cv2.boundingRect(c)[3])]\n",
    "                         for c in contours])\n",
    "    \n",
    "    min_letter_area, max_letter_area = np.percentile(features[:, 1], [10, 90])\n",
    "    letter_arange = np.percentile(features[:, 0], [10, 90])\n",
    "    \n",
    "    mean_vec = np.mean(features, axis=0)\n",
    "    inv_covmat = np.linalg.inv(np.cov(features, rowvar=False))\n",
    "    chi2_threshold = chi2.ppf(quantile, df=3)\n",
    "    \n",
    "    non_letter_mask = np.zeros_like(filtered_image)\n",
    "    for i, contour in enumerate(contours):\n",
    "        md_squared = mahalanobis(features[i], mean_vec, inv_covmat) ** 2\n",
    "        if md_squared > chi2_threshold:\n",
    "            area, aspect_ratio = features[i, 1], features[i, 0]\n",
    "            if min_letter_area <= area <= max_letter_area and letter_arange[0] <= aspect_ratio <= letter_arange[1]:\n",
    "                continue\n",
    "            cv2.drawContours(non_letter_mask, [contour], -1, 255, thickness=cv2.FILLED)\n",
    "    \n",
    "    final_image = cv2.bitwise_and(filtered_image, filtered_image, mask=cv2.bitwise_not(non_letter_mask))\n",
    "    \n",
    "    blurred = cv2.GaussianBlur(final_image, (3, 3), 0)\n",
    "    sharpened = cv2.addWeighted(final_image, 1 + alpha, blurred, -alpha, 0)\n",
    "    _, binary_sharpened = cv2.threshold(sharpened, 128, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    cv2.imwrite(output_path, binary_sharpened)\n",
    "    return binary_sharpened, output_path\n",
    "\n",
    "def process_multiple_images(input_dir, output_dir, threshold=None, quantile=0.99936, alpha=1.5, max_workers=None):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    image_files = [f for f in os.listdir(input_dir) if f.lower().endswith(('png', 'jpg', 'jpeg', 'bmp'))]\n",
    "    input_paths = [os.path.join(input_dir, f) for f in image_files]\n",
    "    output_paths = [os.path.join(output_dir, f) for f in image_files]\n",
    "    \n",
    "    if max_workers is None:\n",
    "        max_workers = min(8, len(image_files))\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        executor.map(process_image, input_paths, output_paths, \n",
    "                     [threshold] * len(input_paths), [quantile] * len(input_paths), [alpha] * len(input_paths))\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == '__main__':\n",
    "    process_multiple_images(\"data\", \"output\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the image in grayscale\n",
    "img = cv2.imread(\"./output/147.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "if img is None:\n",
    "    raise Exception(\"Image not found. Please check the path.\")\n",
    "\n",
    "# Step 1: Ensure we have black text on white background\n",
    "# If the mean pixel value is low (dark image), assume text is white on black and invert.\n",
    "if np.mean(img) < 127:\n",
    "    img = cv2.bitwise_not(img)\n",
    "\n",
    "# Step 2: Enhance contrast using CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "img_clahe = clahe.apply(img)\n",
    "\n",
    "# Step 3: Denoise with a median filter to remove small artifacts\n",
    "img_denoised = cv2.medianBlur(img_clahe, 3)\n",
    "\n",
    "# Step 4: Adaptive thresholding for a crisp binary image\n",
    "img_thresh = cv2.adaptiveThreshold(\n",
    "    img_denoised, \n",
    "    255, \n",
    "    cv2.ADAPTIVE_THRESH_MEAN_C, \n",
    "    cv2.THRESH_BINARY, \n",
    "    11, 2\n",
    ")\n",
    "\n",
    "# Step 5: Morphological closing to connect broken parts of letters\n",
    "kernel = np.ones((3, 3), np.uint8)\n",
    "img_closed = cv2.morphologyEx(img_thresh, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "# Optional: Dilation to thicken strokes slightly (adjust iterations if needed)\n",
    "img_final = cv2.dilate(img_closed, kernel, iterations=1)\n",
    "\n",
    "# Display input and processed images side by side\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.title(\"Input Image\")\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(img_final, cmap='gray')\n",
    "plt.title(\"Processed Image for OCR\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "# Save the processed image\n",
    "cv2.imwrite(\"processed_image.png\", img_final)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
